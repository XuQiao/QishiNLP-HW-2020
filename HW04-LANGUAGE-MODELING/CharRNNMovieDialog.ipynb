{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Personal mid-term small project</center></h1> \n",
    "<h2><center>Character based RNN to generate movie dialog</center></h2>\n",
    "\n",
    "<h2>Overview</h2>\n",
    "I tried to use the public dataset from Cornell Movie-Dialogs Corpus to generate movie dialogs automatically.\n",
    "\n",
    "Since I am very interested in the character based neural network, I tried to use char embedding and RNN(LSTM) to do the language model.\n",
    "\n",
    "First we extract data and get vocabulary, since it is char based, the vocab only contains 82 chars.\n",
    "\n",
    "The framework is very similar as we used in Homework 4, except we generate char by char.\n",
    "\n",
    "<h2>Result</h2>\n",
    "The model architechure is one embedding layer, followed by two LSTM layers with 128 units, then a dense layer with softmax activation.\n",
    "\n",
    "I used 200k sentences to train, each sentences contains average 100 chars. See if we can generate meaningful sentences.\n",
    "\n",
    "The perplexity decreased from 5 to about 2. So the training makes the model has some generative power. First, if we use \"stateless\" models, then it could not generate meaning sentences, and it actually can get the first captial letters correctly. Then if we use \"stateful\" models, then we could get meaning words even sentences, and a lof of the punctuations are correct. So the model actually learning the relationship between English chars very nicely!\n",
    "\n",
    "<h2>To be improved</h2>\n",
    "It is very promising if more time were given and more data is used to train. \n",
    "Also, after I generated meaningful words and sentences, I will try to embedding movie genre and movie cast position to generate more accurate dialogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import keras\n",
    "import json\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv, string\n",
    "from collections import Counter\n",
    "import os, sys, random, re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "- 220,579 conversational exchanges between 10,292 pairs of movie characters\n",
    "- involves 9,035 characters from 617 movies\n",
    "- in total 304,713 utterances\n",
    "- movie metadata included:\n",
    "\t- genres\n",
    "\t- release year\n",
    "\t- IMDB rating\n",
    "\t- number of IMDB votes\n",
    "\t- IMDB rating\n",
    "- character metadata included:\n",
    "\t- gender (for 3,774 characters)\n",
    "\t- position on movie credits (3,321 characters)\n",
    "\n",
    "\n",
    "B) Files description:\n",
    "\n",
    "In all files the field separator is \" +++$+++ \"\n",
    "\n",
    "- movie_titles_metadata.txt\n",
    "\t- contains information about each movie title\n",
    "\t- fields: \n",
    "\t\t- movieID, \n",
    "\t\t- movie title,\n",
    "\t\t- movie year, \n",
    "\t   \t- IMDB rating,\n",
    "\t\t- no. IMDB votes,\n",
    " \t\t- genres in the format ['genre1','genre2',…,'genreN']\n",
    "\n",
    "- movie_characters_metadata.txt\n",
    "\t- contains information about each movie character\n",
    "\t- fields:\n",
    "\t\t- characterID\n",
    "\t\t- character name\n",
    "\t\t- movieID\n",
    "\t\t- movie title\n",
    "\t\t- gender (\"?\" for unlabeled cases)\n",
    "\t\t- position in credits (\"?\" for unlabeled cases) \n",
    "\n",
    "- movie_lines.txt\n",
    "\t- contains the actual text of each utterance\n",
    "\t- fields:\n",
    "\t\t- lineID\n",
    "\t\t- characterID (who uttered this phrase)\n",
    "\t\t- movieID\n",
    "\t\t- character name\n",
    "\t\t- text of the utterance\n",
    "\n",
    "- movie_conversations.txt\n",
    "\t- the structure of the conversations\n",
    "\t- fields\n",
    "\t\t- characterID of the first character involved in the conversation\n",
    "\t\t- characterID of the second character involved in the conversation\n",
    "\t\t- movieID of the movie in which the conversation occurred\n",
    "\t\t- list of the utterances that make the conversation, in chronological \n",
    "\t\t\torder: ['lineID1','lineID2',…,'lineIDN']\n",
    "\t\t\thas to be matched with movie_lines.txt to reconstruct the actual content\n",
    "\n",
    "- raw_script_urls.txt\n",
    "\t- the urls from which the raw sources were retrieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose\n",
    "\n",
    "This program is to generate movie dialog according to the movie genre, and character gender/position in the movie, maybe a \"movie chatbot\" is also an interesting application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./movie-dialog-corpus/movie_lines_formatted.tsv'):\n",
    "    with open('./movie-dialog-corpus/movie_lines.tsv', newline='\\n') as csvfile1:\n",
    "        with open('./movie-dialog-corpus/movie_lines_formatted.tsv','w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter='\\t')\n",
    "            reader = csv.reader(csvfile1, delimiter='\\t', quotechar=None)\n",
    "            for row in reader:\n",
    "                if row[0][0] == '\"':\n",
    "                    row[0] = row[0][1:]\n",
    "                if len(row) > 4:\n",
    "                    row[4] = ' '.join(row[4:])\n",
    "                    row = row[:5]\n",
    "                if row[4] == \"\":\n",
    "                    continue\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles_metadata = pd.read_csv(\"./movie-dialog-corpus/movie_titles_metadata.tsv\", encoding='utf-8-sig', sep=\"\\t\", header = None)\n",
    "movie_lines = pd.read_csv(\"./movie-dialog-corpus/movie_lines_formatted.tsv\", encoding='utf-8-sig', sep=\"\\t\", header = None)\n",
    "movie_conversations = pd.read_csv(\"./movie-dialog-corpus/movie_conversations.tsv\", encoding='utf-8-sig', sep=\"\\t\", header = None)\n",
    "movie_characters_metadata = pd.read_csv(\"./movie-dialog-corpus/movie_characters_metadata.tsv\",  encoding='utf-8-sig', sep=\"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2        3             4\n",
       "0  L1045  u0  m0   BIANCA  They do not!\n",
       "1  L1044  u2  m0  CAMERON   They do to!\n",
       "2   L985  u0  m0   BIANCA    I hope so.\n",
       "3   L984  u2  m0  CAMERON     She okay?\n",
       "4   L925  u0  m0   BIANCA     Let's go."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"<START>\"\n",
    "UNK = \"<UNK>\"\n",
    "END = \"<END>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_char():\n",
    "    \"\"\"\n",
    "    Load the training data into the training format\n",
    "    Return a list of characters\n",
    "    \"\"\"\n",
    "    data = [list(h.strip('\\n')) for h in movie_lines[movie_lines.columns[4]]]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the training data into the training format\n",
    "    remove punctuation and return a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing excess punctuation and newline\n",
    "    pattern = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    data = [pattern.sub('', h.strip(\"\\n\")).split(' ') for h in movie_lines[movie_lines.columns[4]]]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "re_vocab = {}\n",
    "\n",
    "def get_vocab_char():\n",
    "    lines = movie_lines[movie_lines.columns[4]]\n",
    "    total_chars = ''.join(lines)\n",
    "    total_chars = Counter(total_chars)\n",
    "    vocab= [c for c in total_chars if total_chars[c] > 100 and (ord(c) < 120 or ord(c) > 160) ]\n",
    "    return vocab\n",
    "\n",
    "def get_vocab(min_token_ct=0):\n",
    "    \"\"\"\n",
    "    For given training data, list of vocabulary list, i.g.\n",
    "    [[\"this\", \"set\", \"1\"],\n",
    "     [\"this\", \"is\", \"another\", \"set\"],\n",
    "     ]\n",
    "     \n",
    "    return the vocab list and rev_vocab dictionary\n",
    "    3 numerical encodings are reserved: {<UNK>:0, <START>:1, <END>:2}\n",
    "    \"\"\"\n",
    "    lines = load_data()\n",
    "    token_ct = Counter([token for line in lines for token in line])\n",
    "    token_ct = {k: v for k, v in token_ct.items() if v >= min_token_ct}\n",
    "    vocab = sorted(token_ct, key=token_ct.get, reverse=True)\n",
    "        \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 {'<UNK>': 0, '<START>': 1, '<END>': 2, 'T': 3, 'h': 4, 'e': 5, ' ': 6, 'd': 7, 'o': 8, 'n': 9, 't': 10, '!': 11, 'I': 12, 'p': 13, 's': 14, '.': 15, 'S': 16, 'k': 17, 'a': 18, '?': 19, 'L': 20, \"'\": 21, 'g': 22, 'W': 23, 'w': 24, 'O': 25, '-': 26, 'u': 27, 'r': 28, 'l': 29, 'i': 30, 'N': 31, 'm': 32, 'Y': 33, 'j': 34, 'b': 35, 'c': 36, '\"': 37, 'A': 38, 'q': 39, 'f': 40, 'v': 41, 'G': 42, 'M': 43, '9': 44, '0': 45, '2': 46, '1': 47, 'B': 48, 'H': 49, 'C': 50, 'P': 51, 'J': 52, 'E': 53, 'D': 54, 'F': 55, 'R': 56, 'K': 57, 'U': 58, 'Q': 59, ':': 60, 'V': 61, '*': 62, '7': 63, '5': 64, '$': 65, '3': 66, '6': 67, '4': 68, '8': 69, '/': 70, ';': 71, 'Z': 72, 'X': 73, ',': 74, '<': 75, '>': 76, '&': 77, '[': 78, ']': 79, '_': 80, 'í': 81}\n"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab_char()\n",
    "vocab = [UNK, START, END] + vocab\n",
    "re_vocab = {v:k for k,v in enumerate(vocab)}\n",
    "print(len(re_vocab),re_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def to_label(token):\n",
    "    label = re_vocab.get(token, re_vocab[UNK])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dialog(data, batch_size=100, one_hot = True):\n",
    "    # one dialog contains movie genre(a vector of size_g), vector of characters gender/position, and their dialog, tokenized into single chars.\n",
    "    # should be a generator to save memory\n",
    "    # should be LSTM model to preserve long and short memory\n",
    "    \n",
    "    while True:\n",
    "        # Shuffle the data so data order is different for different epochs\n",
    "        random.shuffle(data)\n",
    "        #X: np.array(batch_size, sent_len, embedding_dim)\n",
    "        #Y: np.array(batch_size, sent_len, ) \n",
    "        X, y = [], []\n",
    "        for s in data:\n",
    "            X.append([to_label(START)] + [to_label(t) for t in s])\n",
    "            y.append([to_label(t) for t in s] + [to_label(END)])\n",
    "            if len(X) >= batch_size:   \n",
    "                X = pad_sequences(sequences=X, maxlen=sent_len, padding='post', value=to_label(END))\n",
    "                y = pad_sequences(sequences=y, maxlen=sent_len, padding='post', value=to_label(END))\n",
    "                if one_hot:\n",
    "                    #X = to_categorical(X, num_classes=len(re_vocab))\n",
    "                    y = to_categorical(y, num_classes=len(re_vocab))\n",
    "                yield X, y\n",
    "                \n",
    "                X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_weight(prob): \n",
    "    unk_idx = re_vocab[UNK]\n",
    "    prob[unk_idx] = 0 # Make sure we do not use UNK in the generated text\n",
    "    if prob.sum() <= 0: \n",
    "        prob[1:] = 1.0\n",
    "    return np.random.choice(range(len(prob)), p=prob/prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len = 100 #max([len(s) for s in train_X]) + 1\n",
    "size_c = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "#with open(\"glove.6B/glove.6B.100d.txt\", 'r') as f:\n",
    "with open(\"char-embeddings.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "embedding_matrix = np.zeros((len(vocab), size_c))\n",
    "for word, i in re_vocab.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 19:00:51.767338 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0412 19:00:51.794117 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0412 19:00:51.800951 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          24600     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          219648    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 82)           10578     \n",
      "=================================================================\n",
      "Total params: 386,410\n",
      "Trainable params: 386,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Embedding, LSTM, Activation, TimeDistributed, Reshape, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# For simplicity, we use the embedding of words to feed the model, therefore\n",
    "# no need to add a Embedding layer in the begining. But for a possibly better performance\n",
    "# you can add a embedding layer, even better if you use the glove embedding matrix as the\n",
    "# initial value for the embedding layer\n",
    "# This is useful also because we have filled the embedding with random values for those missing\n",
    "# vocabularies, allowing the embedding matrix to relax during training will improve the performance \n",
    "# for these words as well. But be prepared that this would slow down the training\n",
    "\n",
    "# Unfortunately Keras does not have an easy way to support dynamic length of input for RNN model.\n",
    "# So we use the sent_len to truncate all the sentences.\n",
    "batch_size = 10\n",
    "train_model = Sequential()\n",
    "train_model.add(Embedding(input_dim = len(vocab), output_dim = size_c, input_length = sent_len, trainable = True))\n",
    "train_model.add(LSTM(128, input_shape=(sent_len, len(vocab)), return_sequences=True))\n",
    "train_model.add(LSTM(128, input_shape=(sent_len, len(vocab)), return_sequences=True))\n",
    "train_model.add(TimeDistributed(Dense(len(vocab), activation='softmax')))\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, 1, 300)               24600     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, 1, 128)               219648    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (1, 1, 128)               131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (1, 1, 82)                10578     \n",
      "=================================================================\n",
      "Total params: 386,410\n",
      "Trainable params: 386,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred_model = Sequential()\n",
    "pred_model.add(Embedding(input_dim = len(vocab), output_dim = size_c, batch_input_shape=(1, 1), trainable = True))\n",
    "pred_model.add(LSTM(128, input_shape=(1, len(vocab)), return_sequences=True, stateful = True))\n",
    "pred_model.add(LSTM(128, input_shape=(1, len(vocab)), return_sequences=True, stateful = True))\n",
    "pred_model.add(TimeDistributed(Dense(len(vocab), activation='softmax')))\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, max_len=sent_len-1, seed=None):\n",
    "    if seed is None:\n",
    "        seed = START\n",
    "        result = [] \n",
    "    else:\n",
    "        result = [seed]\n",
    "    model.reset_states()\n",
    "    for i in range(max_len):\n",
    "        X = [[to_label(seed)]]\n",
    "        #X = to_categorical(X, num_classes=len(re_vocab))\n",
    "        idx = sample_with_weight(model.predict(X)[0][0])\n",
    "        if vocab[idx] in [START, UNK, END]: \n",
    "            break \n",
    "        seed = vocab[idx]\n",
    "        result.append(seed)\n",
    "    return ''.join(result)  # char based  \n",
    "    #return ' '.join(result) # word based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 19:00:53.262310 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0412 19:00:53.264347 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'acZ>>EN]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(pred_model, seed='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_embedding(size_g):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_embedding(size_c):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, X, y):\n",
    "    #prob = model.predict(to_categorical(X, len(vocab))) \n",
    "    prob = model.predict(X) \n",
    "    M = 0\n",
    "    P = 0\n",
    "    N, sent_len = y.shape\n",
    "    for s in range(N):\n",
    "        for l in range(sent_len):\n",
    "            if y[s,l] in [re_vocab[END]]: \n",
    "                break\n",
    "            P += np.log(prob[s,l,y[s,l]]) \n",
    "            M += 1\n",
    "    perplexity = np.exp(-P/M)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, dev_X = train_test_split(load_data_char(), test_size=0.33, shuffle = True)\n",
    "dev_X, dev_y = next(generate_dialog(dev_X, batch_size=-1, one_hot = False))\n",
    "train_X = train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 19:00:56.583560 4716780992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0412 19:00:56.786028 4716780992 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20398/20398 [==============================] - 3547s 174ms/step - loss: 0.7109\n",
      "----- Generating text after Epoch: 1\n",
      "Oh I'm on impoiss close.\n",
      "You didn't hope this perfect seak.\n",
      "I forgot another airman.\n",
      "Well because I had staiding an opant in for us. You dear....\n",
      "Taking new of the job?\n",
      "Current perplexity on dev data:  4.028639752313307 \n",
      "\n",
      "Epoch 2/10\n",
      "20398/20398 [==============================] - 3446s 169ms/step - loss: 0.6171\n",
      "----- Generating text after Epoch: 2\n",
      "Your mother. We can unlosal foors?\n",
      "Goodboe that another daumber in the maish.\n",
      "Make a miles are comes.\n",
      "Aren't that fuckin' loader?\n",
      "It's noan in the free number make.\n",
      "Current perplexity on dev data:  4.249186407965177 \n",
      "\n",
      "Epoch 3/10\n",
      "20398/20398 [==============================] - 3192s 156ms/step - loss: 0.6028\n",
      "----- Generating text after Epoch: 3\n",
      "Neighment Gaboo.\n",
      "Cool and I was going to then --\n",
      "What does the familioon?'\n",
      "How'd --\n",
      "Well since I turrened to the important stupidaced.\n",
      "Current perplexity on dev data:  3.5413985658892724 \n",
      "\n",
      "Epoch 4/10\n",
      "20398/20398 [==============================] - 3278s 161ms/step - loss: 0.5955\n",
      "----- Generating text after Epoch: 4\n",
      "How girl. Calleus who would give me a week?\n",
      "Hello Life these pressure.\n",
      "This shakes in pardin killed Tockled.\n",
      "Look I've told then. College.\n",
      "You been' heart of Zaul?\n",
      "Current perplexity on dev data:  3.6433960554576776 \n",
      "\n",
      "Epoch 5/10\n",
      "20398/20398 [==============================] - 3143s 154ms/step - loss: 0.5907\n",
      "----- Generating text after Epoch: 5\n",
      "Yes.  Did not believe the law of work to CTWELWAK united Jimme.\n",
      "If the other mission Javishs and falls to trafeling. You loved his mother?\n",
      "You don't understand!\n",
      "Listen.\n",
      "Mernettia.  Spirit I have.\n",
      "Current perplexity on dev data:  3.6165832922578116 \n",
      "\n",
      "Epoch 6/10\n",
      "20398/20398 [==============================] - 3099s 152ms/step - loss: 0.5874\n",
      "----- Generating text after Epoch: 6\n",
      "What's not?\n",
      "Well it haddeading is what the 'im admit what he's still not the brain?\n",
      "Could know eatell.\"\n",
      "And do but she's funnite engid that studiots.\n",
      "How man is that?\n",
      "Current perplexity on dev data:  3.467740390727447 \n",
      "\n",
      "Epoch 7/10\n",
      "20398/20398 [==============================] - 3107s 152ms/step - loss: 0.5849\n",
      "----- Generating text after Epoch: 7\n",
      "Roba Cars.\n",
      "Seat again.\n",
      "Cartred's mother not.\n",
      "If that's more than the truth.\n",
      "We...\n",
      "Current perplexity on dev data:  3.7304578710895524 \n",
      "\n",
      "Epoch 8/10\n",
      "20398/20398 [==============================] - 3104s 152ms/step - loss: 0.5829\n",
      "----- Generating text after Epoch: 8\n",
      "It's FEC:Yaing.\n",
      "It is... three he saved me taw-nine.\n",
      "That answens familia!\n",
      "You're torn.   I haven't done me!\n",
      "Would that be too sweetheart' best second this?\n",
      "Current perplexity on dev data:  3.3627057264822744 \n",
      "\n",
      "Epoch 9/10\n",
      "20398/20398 [==============================] - 6536s 320ms/step - loss: 0.5813\n",
      "----- Generating text after Epoch: 9\n",
      "Give him the motive dent on a taking basic reed? I should be embarraged.\n",
      "Nobodautes. Shapper his pain chritch if a sure on real enuails her coters.  You're diffeing smashmo\n",
      "What do we wib? What do I do?\n",
      "I'm sure it starts and eat their stareds are leaved a great postsaust rings soon but what happened?\n",
      "There's coming to state and a world fremb and seems it.\n",
      "Current perplexity on dev data:  3.3453610410392924 \n",
      "\n",
      "Epoch 10/10\n",
      "20398/20398 [==============================] - 5088s 249ms/step - loss: 0.5799\n",
      "----- Generating text after Epoch: 10\n",
      "Oh much about a  the ware entering woman.\n",
      "Can't have an operation.\n",
      "You think we go coff he good sta make a cliful far?\n",
      "What now?\n",
      "Now later.\n",
      "Current perplexity on dev data:  3.491889510312319 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fb15e48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "def on_epoch_end(epoch, logs):\n",
    "    pred_model.set_weights(train_model.get_weights())\n",
    "    print('----- Generating text after Epoch: %d' % (epoch + 1))\n",
    "    for i in range(5):\n",
    "        print(generate_text(pred_model))\n",
    "    print('Current perplexity on dev data: ', \n",
    "          calculate_perplexity(train_model, dev_X, dev_y), '\\n')\n",
    "    \n",
    "from keras.callbacks import LambdaCallback\n",
    "\"\"\"\n",
    "Notice how the metrics / generated text evolve after each epoch\n",
    "\"\"\"\n",
    "batch_size = 10\n",
    "num_batches = len(train_X) // batch_size \n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "train_model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "train_model.fit_generator(generate_dialog(train_X, batch_size), num_batches, 10,\n",
    "          callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
